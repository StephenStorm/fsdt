** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

Command Line Args: Namespace(config_file='configs/PascalVOC-detection/split1/faster_rcnn_R_101_FPN_ft_all1_2shot.yaml', dist_url='tcp://127.0.0.1:50157', end_iter=-1, eval_all=False, eval_during_train=False, eval_iter=-1, eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=None, resume=False, start_iter=-1)
** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

[32m[07/09 23:04:38 detectron2]: [0mRank of current process: 0. World size: 2
[32m[07/09 23:04:38 detectron2]: [0mCommand line arguments: Namespace(config_file='configs/PascalVOC-detection/split1/faster_rcnn_R_101_FPN_ft_all1_2shot.yaml', dist_url='tcp://127.0.0.1:50157', end_iter=-1, eval_all=False, eval_during_train=False, eval_iter=-1, eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=None, resume=False, start_iter=-1)
[32m[07/09 23:04:38 detectron2]: [0mContents of args.config_file=configs/PascalVOC-detection/split1/faster_rcnn_R_101_FPN_ft_all1_2shot.yaml:
_BASE_: "../../Base-RCNN-FPN.yaml"
MODEL:
  WEIGHTS: "/home/zhanglibin/workspace/FSOD/few-shot-object-detection/weights/R-101.pkl"
  MASK_ON: False
  RESNETS:
    DEPTH: 101
  ROI_HEADS:
    NUM_CLASSES: 20
    OUTPUT_LAYER: "CosineSimOutputLayers"
    FREEZE_FEAT: True
  BACKBONE:
    FREEZE: True
  PROPOSAL_GENERATOR:
    FREEZE: True
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MIN_SIZE_TEST: 800
DATASETS:
  # TRAIN: ('voc_2007_trainval_all1_2shot',)
  TRAIN: ('voc_2007_trainval_all1_2shot_seed4',)
  TEST: ('voc_2007_test_all1',)
SOLVER:
  IMS_PER_BATCH: 32
  BASE_LR: 0.001
  STEPS: (7000,)
  MAX_ITER: 8000
  CHECKPOINT_PERIOD: 500
  WARMUP_ITERS: 0
OUTPUT_DIR: "checkpoints/voc/faster_rcnn/faster_rcnn_R_101_FPN_ft_normalized_all1_2shot_randnovel"
[32m[07/09 23:04:38 detectron2]: [0mFull config saved to /home/zhanglibin/workspace/FSOD/few-shot-object-detection/checkpoints/voc/faster_rcnn/faster_rcnn_R_101_FPN_ft_normalized_all1_2shot_randnovel/config.yaml
[32m[07/09 23:04:38 d2.utils.env]: [0mUsing a generated random seed 38771866
froze backbone parameters
froze proposal generator parameters
froze roi_box_head parameters
--------------------------------------------------------------------
voc_2007_trainval_all1_2shot_seed4
datasets/VOC2007
all_2shot_split_1_trainval
['aeroplane', 'bicycle', 'boat', 'bottle', 'car', 'cat', 'chair', 'diningtable', 'dog', 'horse', 'person', 'pottedplant', 'sheep', 'train', 'tvmonitor', 'bird', 'bus', 'cow', 'motorbike', 'sofa']
--------------------------------------------------------------------
[32m[07/09 23:04:39 d2.data.build]: [0mRemoved 0 images with no usable annotations. 40 images left.
[32m[07/09 23:04:39 d2.data.build]: [0mDistribution of instances among all 20 categories:
[36m|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 2            |   bicycle   | 2            |    boat     | 2            |
|   bottle   | 2            |     car     | 2            |     cat     | 2            |
|   chair    | 2            | diningtable | 2            |     dog     | 2            |
|   horse    | 2            |   person    | 2            | pottedplant | 2            |
|   sheep    | 2            |    train    | 2            |  tvmonitor  | 2            |
|    bird    | 2            |     bus     | 2            |     cow     | 2            |
| motorbike  | 2            |    sofa     | 2            |             |              |
|   total    | 40           |             |              |             |              |[0m
[32m[07/09 23:04:39 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[07/09 23:04:39 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[07/09 23:04:39 d2.data.common]: [0mSerializing 40 elements to byte tensors and concatenating them all ...
[32m[07/09 23:04:39 d2.data.common]: [0mSerialized dataset takes 0.01 MiB
[32m[07/09 23:04:39 fvcore.common.checkpoint]: [0mLoading checkpoint from /home/zhanglibin/workspace/FSOD/few-shot-object-detection/weights/R-101.pkl
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mRemapping C2 weights ......
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.0.conv1.norm.bias            loaded from res2_0_branch2a_bn_b        of shape (64,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.0.conv1.norm.weight          loaded from res2_0_branch2a_bn_s        of shape (64,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.0.conv1.weight               loaded from res2_0_branch2a_w           of shape (64, 64, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.0.conv2.norm.bias            loaded from res2_0_branch2b_bn_b        of shape (64,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.0.conv2.norm.weight          loaded from res2_0_branch2b_bn_s        of shape (64,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.0.conv2.weight               loaded from res2_0_branch2b_w           of shape (64, 64, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.0.conv3.norm.bias            loaded from res2_0_branch2c_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.0.conv3.norm.weight          loaded from res2_0_branch2c_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.0.conv3.weight               loaded from res2_0_branch2c_w           of shape (256, 64, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.0.shortcut.norm.bias         loaded from res2_0_branch1_bn_b         of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.0.shortcut.norm.weight       loaded from res2_0_branch1_bn_s         of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.0.shortcut.weight            loaded from res2_0_branch1_w            of shape (256, 64, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.1.conv1.norm.bias            loaded from res2_1_branch2a_bn_b        of shape (64,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.1.conv1.norm.weight          loaded from res2_1_branch2a_bn_s        of shape (64,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.1.conv1.weight               loaded from res2_1_branch2a_w           of shape (64, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.1.conv2.norm.bias            loaded from res2_1_branch2b_bn_b        of shape (64,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.1.conv2.norm.weight          loaded from res2_1_branch2b_bn_s        of shape (64,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.1.conv2.weight               loaded from res2_1_branch2b_w           of shape (64, 64, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.1.conv3.norm.bias            loaded from res2_1_branch2c_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.1.conv3.norm.weight          loaded from res2_1_branch2c_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.1.conv3.weight               loaded from res2_1_branch2c_w           of shape (256, 64, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.2.conv1.norm.bias            loaded from res2_2_branch2a_bn_b        of shape (64,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.2.conv1.norm.weight          loaded from res2_2_branch2a_bn_s        of shape (64,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.2.conv1.weight               loaded from res2_2_branch2a_w           of shape (64, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.2.conv2.norm.bias            loaded from res2_2_branch2b_bn_b        of shape (64,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.2.conv2.norm.weight          loaded from res2_2_branch2b_bn_s        of shape (64,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.2.conv2.weight               loaded from res2_2_branch2b_w           of shape (64, 64, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.2.conv3.norm.bias            loaded from res2_2_branch2c_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.2.conv3.norm.weight          loaded from res2_2_branch2c_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res2.2.conv3.weight               loaded from res2_2_branch2c_w           of shape (256, 64, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.0.conv1.norm.bias            loaded from res3_0_branch2a_bn_b        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.0.conv1.norm.weight          loaded from res3_0_branch2a_bn_s        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.0.conv1.weight               loaded from res3_0_branch2a_w           of shape (128, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.0.conv2.norm.bias            loaded from res3_0_branch2b_bn_b        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.0.conv2.norm.weight          loaded from res3_0_branch2b_bn_s        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.0.conv2.weight               loaded from res3_0_branch2b_w           of shape (128, 128, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.0.conv3.norm.bias            loaded from res3_0_branch2c_bn_b        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.0.conv3.norm.weight          loaded from res3_0_branch2c_bn_s        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.0.conv3.weight               loaded from res3_0_branch2c_w           of shape (512, 128, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.0.shortcut.norm.bias         loaded from res3_0_branch1_bn_b         of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.0.shortcut.norm.weight       loaded from res3_0_branch1_bn_s         of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.0.shortcut.weight            loaded from res3_0_branch1_w            of shape (512, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.1.conv1.norm.bias            loaded from res3_1_branch2a_bn_b        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.1.conv1.norm.weight          loaded from res3_1_branch2a_bn_s        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.1.conv1.weight               loaded from res3_1_branch2a_w           of shape (128, 512, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.1.conv2.norm.bias            loaded from res3_1_branch2b_bn_b        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.1.conv2.norm.weight          loaded from res3_1_branch2b_bn_s        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.1.conv2.weight               loaded from res3_1_branch2b_w           of shape (128, 128, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.1.conv3.norm.bias            loaded from res3_1_branch2c_bn_b        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.1.conv3.norm.weight          loaded from res3_1_branch2c_bn_s        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.1.conv3.weight               loaded from res3_1_branch2c_w           of shape (512, 128, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.2.conv1.norm.bias            loaded from res3_2_branch2a_bn_b        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.2.conv1.norm.weight          loaded from res3_2_branch2a_bn_s        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.2.conv1.weight               loaded from res3_2_branch2a_w           of shape (128, 512, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.2.conv2.norm.bias            loaded from res3_2_branch2b_bn_b        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.2.conv2.norm.weight          loaded from res3_2_branch2b_bn_s        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.2.conv2.weight               loaded from res3_2_branch2b_w           of shape (128, 128, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.2.conv3.norm.bias            loaded from res3_2_branch2c_bn_b        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.2.conv3.norm.weight          loaded from res3_2_branch2c_bn_s        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.2.conv3.weight               loaded from res3_2_branch2c_w           of shape (512, 128, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.3.conv1.norm.bias            loaded from res3_3_branch2a_bn_b        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.3.conv1.norm.weight          loaded from res3_3_branch2a_bn_s        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.3.conv1.weight               loaded from res3_3_branch2a_w           of shape (128, 512, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.3.conv2.norm.bias            loaded from res3_3_branch2b_bn_b        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.3.conv2.norm.weight          loaded from res3_3_branch2b_bn_s        of shape (128,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.3.conv2.weight               loaded from res3_3_branch2b_w           of shape (128, 128, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.3.conv3.norm.bias            loaded from res3_3_branch2c_bn_b        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.3.conv3.norm.weight          loaded from res3_3_branch2c_bn_s        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res3.3.conv3.weight               loaded from res3_3_branch2c_w           of shape (512, 128, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.0.conv1.norm.bias            loaded from res4_0_branch2a_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.0.conv1.norm.weight          loaded from res4_0_branch2a_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.0.conv1.weight               loaded from res4_0_branch2a_w           of shape (256, 512, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.0.conv2.norm.bias            loaded from res4_0_branch2b_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.0.conv2.norm.weight          loaded from res4_0_branch2b_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.0.conv2.weight               loaded from res4_0_branch2b_w           of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.0.conv3.norm.bias            loaded from res4_0_branch2c_bn_b        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.0.conv3.norm.weight          loaded from res4_0_branch2c_bn_s        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.0.conv3.weight               loaded from res4_0_branch2c_w           of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.0.shortcut.norm.bias         loaded from res4_0_branch1_bn_b         of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.0.shortcut.norm.weight       loaded from res4_0_branch1_bn_s         of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.0.shortcut.weight            loaded from res4_0_branch1_w            of shape (1024, 512, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.1.conv1.norm.bias            loaded from res4_1_branch2a_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.1.conv1.norm.weight          loaded from res4_1_branch2a_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.1.conv1.weight               loaded from res4_1_branch2a_w           of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.1.conv2.norm.bias            loaded from res4_1_branch2b_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.1.conv2.norm.weight          loaded from res4_1_branch2b_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.1.conv2.weight               loaded from res4_1_branch2b_w           of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.1.conv3.norm.bias            loaded from res4_1_branch2c_bn_b        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.1.conv3.norm.weight          loaded from res4_1_branch2c_bn_s        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.1.conv3.weight               loaded from res4_1_branch2c_w           of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.10.conv1.norm.bias           loaded from res4_10_branch2a_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.10.conv1.norm.weight         loaded from res4_10_branch2a_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.10.conv1.weight              loaded from res4_10_branch2a_w          of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.10.conv2.norm.bias           loaded from res4_10_branch2b_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.10.conv2.norm.weight         loaded from res4_10_branch2b_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.10.conv2.weight              loaded from res4_10_branch2b_w          of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.10.conv3.norm.bias           loaded from res4_10_branch2c_bn_b       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.10.conv3.norm.weight         loaded from res4_10_branch2c_bn_s       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.10.conv3.weight              loaded from res4_10_branch2c_w          of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.11.conv1.norm.bias           loaded from res4_11_branch2a_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.11.conv1.norm.weight         loaded from res4_11_branch2a_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.11.conv1.weight              loaded from res4_11_branch2a_w          of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.11.conv2.norm.bias           loaded from res4_11_branch2b_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.11.conv2.norm.weight         loaded from res4_11_branch2b_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.11.conv2.weight              loaded from res4_11_branch2b_w          of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.11.conv3.norm.bias           loaded from res4_11_branch2c_bn_b       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.11.conv3.norm.weight         loaded from res4_11_branch2c_bn_s       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.11.conv3.weight              loaded from res4_11_branch2c_w          of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.12.conv1.norm.bias           loaded from res4_12_branch2a_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.12.conv1.norm.weight         loaded from res4_12_branch2a_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.12.conv1.weight              loaded from res4_12_branch2a_w          of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.12.conv2.norm.bias           loaded from res4_12_branch2b_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.12.conv2.norm.weight         loaded from res4_12_branch2b_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.12.conv2.weight              loaded from res4_12_branch2b_w          of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.12.conv3.norm.bias           loaded from res4_12_branch2c_bn_b       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.12.conv3.norm.weight         loaded from res4_12_branch2c_bn_s       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.12.conv3.weight              loaded from res4_12_branch2c_w          of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.13.conv1.norm.bias           loaded from res4_13_branch2a_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.13.conv1.norm.weight         loaded from res4_13_branch2a_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.13.conv1.weight              loaded from res4_13_branch2a_w          of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.13.conv2.norm.bias           loaded from res4_13_branch2b_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.13.conv2.norm.weight         loaded from res4_13_branch2b_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.13.conv2.weight              loaded from res4_13_branch2b_w          of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.13.conv3.norm.bias           loaded from res4_13_branch2c_bn_b       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.13.conv3.norm.weight         loaded from res4_13_branch2c_bn_s       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.13.conv3.weight              loaded from res4_13_branch2c_w          of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.14.conv1.norm.bias           loaded from res4_14_branch2a_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.14.conv1.norm.weight         loaded from res4_14_branch2a_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.14.conv1.weight              loaded from res4_14_branch2a_w          of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.14.conv2.norm.bias           loaded from res4_14_branch2b_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.14.conv2.norm.weight         loaded from res4_14_branch2b_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.14.conv2.weight              loaded from res4_14_branch2b_w          of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.14.conv3.norm.bias           loaded from res4_14_branch2c_bn_b       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.14.conv3.norm.weight         loaded from res4_14_branch2c_bn_s       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.14.conv3.weight              loaded from res4_14_branch2c_w          of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.15.conv1.norm.bias           loaded from res4_15_branch2a_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.15.conv1.norm.weight         loaded from res4_15_branch2a_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.15.conv1.weight              loaded from res4_15_branch2a_w          of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.15.conv2.norm.bias           loaded from res4_15_branch2b_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.15.conv2.norm.weight         loaded from res4_15_branch2b_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.15.conv2.weight              loaded from res4_15_branch2b_w          of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.15.conv3.norm.bias           loaded from res4_15_branch2c_bn_b       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.15.conv3.norm.weight         loaded from res4_15_branch2c_bn_s       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.15.conv3.weight              loaded from res4_15_branch2c_w          of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.16.conv1.norm.bias           loaded from res4_16_branch2a_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.16.conv1.norm.weight         loaded from res4_16_branch2a_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.16.conv1.weight              loaded from res4_16_branch2a_w          of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.16.conv2.norm.bias           loaded from res4_16_branch2b_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.16.conv2.norm.weight         loaded from res4_16_branch2b_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.16.conv2.weight              loaded from res4_16_branch2b_w          of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.16.conv3.norm.bias           loaded from res4_16_branch2c_bn_b       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.16.conv3.norm.weight         loaded from res4_16_branch2c_bn_s       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.16.conv3.weight              loaded from res4_16_branch2c_w          of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.17.conv1.norm.bias           loaded from res4_17_branch2a_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.17.conv1.norm.weight         loaded from res4_17_branch2a_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.17.conv1.weight              loaded from res4_17_branch2a_w          of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.17.conv2.norm.bias           loaded from res4_17_branch2b_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.17.conv2.norm.weight         loaded from res4_17_branch2b_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.17.conv2.weight              loaded from res4_17_branch2b_w          of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.17.conv3.norm.bias           loaded from res4_17_branch2c_bn_b       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.17.conv3.norm.weight         loaded from res4_17_branch2c_bn_s       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.17.conv3.weight              loaded from res4_17_branch2c_w          of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.18.conv1.norm.bias           loaded from res4_18_branch2a_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.18.conv1.norm.weight         loaded from res4_18_branch2a_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.18.conv1.weight              loaded from res4_18_branch2a_w          of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.18.conv2.norm.bias           loaded from res4_18_branch2b_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.18.conv2.norm.weight         loaded from res4_18_branch2b_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.18.conv2.weight              loaded from res4_18_branch2b_w          of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.18.conv3.norm.bias           loaded from res4_18_branch2c_bn_b       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.18.conv3.norm.weight         loaded from res4_18_branch2c_bn_s       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.18.conv3.weight              loaded from res4_18_branch2c_w          of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.19.conv1.norm.bias           loaded from res4_19_branch2a_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.19.conv1.norm.weight         loaded from res4_19_branch2a_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.19.conv1.weight              loaded from res4_19_branch2a_w          of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.19.conv2.norm.bias           loaded from res4_19_branch2b_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.19.conv2.norm.weight         loaded from res4_19_branch2b_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.19.conv2.weight              loaded from res4_19_branch2b_w          of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.19.conv3.norm.bias           loaded from res4_19_branch2c_bn_b       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.19.conv3.norm.weight         loaded from res4_19_branch2c_bn_s       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.19.conv3.weight              loaded from res4_19_branch2c_w          of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.2.conv1.norm.bias            loaded from res4_2_branch2a_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.2.conv1.norm.weight          loaded from res4_2_branch2a_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.2.conv1.weight               loaded from res4_2_branch2a_w           of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.2.conv2.norm.bias            loaded from res4_2_branch2b_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.2.conv2.norm.weight          loaded from res4_2_branch2b_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.2.conv2.weight               loaded from res4_2_branch2b_w           of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.2.conv3.norm.bias            loaded from res4_2_branch2c_bn_b        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.2.conv3.norm.weight          loaded from res4_2_branch2c_bn_s        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.2.conv3.weight               loaded from res4_2_branch2c_w           of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.20.conv1.norm.bias           loaded from res4_20_branch2a_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.20.conv1.norm.weight         loaded from res4_20_branch2a_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.20.conv1.weight              loaded from res4_20_branch2a_w          of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.20.conv2.norm.bias           loaded from res4_20_branch2b_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.20.conv2.norm.weight         loaded from res4_20_branch2b_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.20.conv2.weight              loaded from res4_20_branch2b_w          of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.20.conv3.norm.bias           loaded from res4_20_branch2c_bn_b       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.20.conv3.norm.weight         loaded from res4_20_branch2c_bn_s       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.20.conv3.weight              loaded from res4_20_branch2c_w          of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.21.conv1.norm.bias           loaded from res4_21_branch2a_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.21.conv1.norm.weight         loaded from res4_21_branch2a_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.21.conv1.weight              loaded from res4_21_branch2a_w          of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.21.conv2.norm.bias           loaded from res4_21_branch2b_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.21.conv2.norm.weight         loaded from res4_21_branch2b_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.21.conv2.weight              loaded from res4_21_branch2b_w          of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.21.conv3.norm.bias           loaded from res4_21_branch2c_bn_b       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.21.conv3.norm.weight         loaded from res4_21_branch2c_bn_s       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.21.conv3.weight              loaded from res4_21_branch2c_w          of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.22.conv1.norm.bias           loaded from res4_22_branch2a_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.22.conv1.norm.weight         loaded from res4_22_branch2a_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.22.conv1.weight              loaded from res4_22_branch2a_w          of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.22.conv2.norm.bias           loaded from res4_22_branch2b_bn_b       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.22.conv2.norm.weight         loaded from res4_22_branch2b_bn_s       of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.22.conv2.weight              loaded from res4_22_branch2b_w          of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.22.conv3.norm.bias           loaded from res4_22_branch2c_bn_b       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.22.conv3.norm.weight         loaded from res4_22_branch2c_bn_s       of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.22.conv3.weight              loaded from res4_22_branch2c_w          of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.3.conv1.norm.bias            loaded from res4_3_branch2a_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.3.conv1.norm.weight          loaded from res4_3_branch2a_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.3.conv1.weight               loaded from res4_3_branch2a_w           of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.3.conv2.norm.bias            loaded from res4_3_branch2b_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.3.conv2.norm.weight          loaded from res4_3_branch2b_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.3.conv2.weight               loaded from res4_3_branch2b_w           of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.3.conv3.norm.bias            loaded from res4_3_branch2c_bn_b        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.3.conv3.norm.weight          loaded from res4_3_branch2c_bn_s        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.3.conv3.weight               loaded from res4_3_branch2c_w           of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.4.conv1.norm.bias            loaded from res4_4_branch2a_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.4.conv1.norm.weight          loaded from res4_4_branch2a_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.4.conv1.weight               loaded from res4_4_branch2a_w           of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.4.conv2.norm.bias            loaded from res4_4_branch2b_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.4.conv2.norm.weight          loaded from res4_4_branch2b_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.4.conv2.weight               loaded from res4_4_branch2b_w           of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.4.conv3.norm.bias            loaded from res4_4_branch2c_bn_b        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.4.conv3.norm.weight          loaded from res4_4_branch2c_bn_s        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.4.conv3.weight               loaded from res4_4_branch2c_w           of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.5.conv1.norm.bias            loaded from res4_5_branch2a_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.5.conv1.norm.weight          loaded from res4_5_branch2a_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.5.conv1.weight               loaded from res4_5_branch2a_w           of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.5.conv2.norm.bias            loaded from res4_5_branch2b_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.5.conv2.norm.weight          loaded from res4_5_branch2b_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.5.conv2.weight               loaded from res4_5_branch2b_w           of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.5.conv3.norm.bias            loaded from res4_5_branch2c_bn_b        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.5.conv3.norm.weight          loaded from res4_5_branch2c_bn_s        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.5.conv3.weight               loaded from res4_5_branch2c_w           of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.6.conv1.norm.bias            loaded from res4_6_branch2a_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.6.conv1.norm.weight          loaded from res4_6_branch2a_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.6.conv1.weight               loaded from res4_6_branch2a_w           of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.6.conv2.norm.bias            loaded from res4_6_branch2b_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.6.conv2.norm.weight          loaded from res4_6_branch2b_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.6.conv2.weight               loaded from res4_6_branch2b_w           of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.6.conv3.norm.bias            loaded from res4_6_branch2c_bn_b        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.6.conv3.norm.weight          loaded from res4_6_branch2c_bn_s        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.6.conv3.weight               loaded from res4_6_branch2c_w           of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.7.conv1.norm.bias            loaded from res4_7_branch2a_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.7.conv1.norm.weight          loaded from res4_7_branch2a_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.7.conv1.weight               loaded from res4_7_branch2a_w           of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.7.conv2.norm.bias            loaded from res4_7_branch2b_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.7.conv2.norm.weight          loaded from res4_7_branch2b_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.7.conv2.weight               loaded from res4_7_branch2b_w           of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.7.conv3.norm.bias            loaded from res4_7_branch2c_bn_b        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.7.conv3.norm.weight          loaded from res4_7_branch2c_bn_s        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.7.conv3.weight               loaded from res4_7_branch2c_w           of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.8.conv1.norm.bias            loaded from res4_8_branch2a_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.8.conv1.norm.weight          loaded from res4_8_branch2a_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.8.conv1.weight               loaded from res4_8_branch2a_w           of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.8.conv2.norm.bias            loaded from res4_8_branch2b_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.8.conv2.norm.weight          loaded from res4_8_branch2b_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.8.conv2.weight               loaded from res4_8_branch2b_w           of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.8.conv3.norm.bias            loaded from res4_8_branch2c_bn_b        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.8.conv3.norm.weight          loaded from res4_8_branch2c_bn_s        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.8.conv3.weight               loaded from res4_8_branch2c_w           of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.9.conv1.norm.bias            loaded from res4_9_branch2a_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.9.conv1.norm.weight          loaded from res4_9_branch2a_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.9.conv1.weight               loaded from res4_9_branch2a_w           of shape (256, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.9.conv2.norm.bias            loaded from res4_9_branch2b_bn_b        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.9.conv2.norm.weight          loaded from res4_9_branch2b_bn_s        of shape (256,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.9.conv2.weight               loaded from res4_9_branch2b_w           of shape (256, 256, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.9.conv3.norm.bias            loaded from res4_9_branch2c_bn_b        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.9.conv3.norm.weight          loaded from res4_9_branch2c_bn_s        of shape (1024,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res4.9.conv3.weight               loaded from res4_9_branch2c_w           of shape (1024, 256, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.0.conv1.norm.bias            loaded from res5_0_branch2a_bn_b        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.0.conv1.norm.weight          loaded from res5_0_branch2a_bn_s        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.0.conv1.weight               loaded from res5_0_branch2a_w           of shape (512, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.0.conv2.norm.bias            loaded from res5_0_branch2b_bn_b        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.0.conv2.norm.weight          loaded from res5_0_branch2b_bn_s        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.0.conv2.weight               loaded from res5_0_branch2b_w           of shape (512, 512, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.0.conv3.norm.bias            loaded from res5_0_branch2c_bn_b        of shape (2048,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.0.conv3.norm.weight          loaded from res5_0_branch2c_bn_s        of shape (2048,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.0.conv3.weight               loaded from res5_0_branch2c_w           of shape (2048, 512, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.0.shortcut.norm.bias         loaded from res5_0_branch1_bn_b         of shape (2048,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.0.shortcut.norm.weight       loaded from res5_0_branch1_bn_s         of shape (2048,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.0.shortcut.weight            loaded from res5_0_branch1_w            of shape (2048, 1024, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.1.conv1.norm.bias            loaded from res5_1_branch2a_bn_b        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.1.conv1.norm.weight          loaded from res5_1_branch2a_bn_s        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.1.conv1.weight               loaded from res5_1_branch2a_w           of shape (512, 2048, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.1.conv2.norm.bias            loaded from res5_1_branch2b_bn_b        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.1.conv2.norm.weight          loaded from res5_1_branch2b_bn_s        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.1.conv2.weight               loaded from res5_1_branch2b_w           of shape (512, 512, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.1.conv3.norm.bias            loaded from res5_1_branch2c_bn_b        of shape (2048,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.1.conv3.norm.weight          loaded from res5_1_branch2c_bn_s        of shape (2048,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.1.conv3.weight               loaded from res5_1_branch2c_w           of shape (2048, 512, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.2.conv1.norm.bias            loaded from res5_2_branch2a_bn_b        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.2.conv1.norm.weight          loaded from res5_2_branch2a_bn_s        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.2.conv1.weight               loaded from res5_2_branch2a_w           of shape (512, 2048, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.2.conv2.norm.bias            loaded from res5_2_branch2b_bn_b        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.2.conv2.norm.weight          loaded from res5_2_branch2b_bn_s        of shape (512,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.2.conv2.weight               loaded from res5_2_branch2b_w           of shape (512, 512, 3, 3)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.2.conv3.norm.bias            loaded from res5_2_branch2c_bn_b        of shape (2048,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.2.conv3.norm.weight          loaded from res5_2_branch2c_bn_s        of shape (2048,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.res5.2.conv3.weight               loaded from res5_2_branch2c_w           of shape (2048, 512, 1, 1)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.stem.conv1.norm.bias              loaded from res_conv1_bn_b              of shape (64,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.stem.conv1.norm.weight            loaded from res_conv1_bn_s              of shape (64,)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mbackbone.bottom_up.stem.conv1.weight                 loaded from conv1_w                     of shape (64, 3, 7, 7)
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mSome model parameters or buffers are not found in the checkpoint:
  [34mbackbone.bottom_up.res2.0.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res2.0.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res2.0.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res2.0.shortcut.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res2.1.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res2.1.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res2.1.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res2.2.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res2.2.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res2.2.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res3.0.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res3.0.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res3.0.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res3.0.shortcut.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res3.1.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res3.1.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res3.1.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res3.2.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res3.2.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res3.2.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res3.3.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res3.3.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res3.3.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.0.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.0.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.0.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.0.shortcut.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.1.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.1.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.1.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.10.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.10.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.10.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.11.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.11.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.11.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.12.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.12.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.12.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.13.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.13.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.13.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.14.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.14.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.14.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.15.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.15.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.15.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.16.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.16.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.16.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.17.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.17.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.17.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.18.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.18.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.18.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.19.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.19.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.19.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.2.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.2.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.2.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.20.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.20.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.20.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.21.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.21.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.21.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.22.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.22.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.22.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.3.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.3.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.3.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.4.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.4.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.4.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.5.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.5.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.5.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.6.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.6.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.6.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.7.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.7.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.7.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.8.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.8.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.8.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.9.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.9.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res4.9.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res5.0.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res5.0.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res5.0.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res5.0.shortcut.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res5.1.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res5.1.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res5.1.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res5.2.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res5.2.conv2.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.res5.2.conv3.norm.{running_mean, running_var}[0m
  [34mbackbone.bottom_up.stem.conv1.norm.{running_mean, running_var}[0m
  [34mbackbone.fpn_lateral2.{bias, weight}[0m
  [34mbackbone.fpn_lateral3.{bias, weight}[0m
  [34mbackbone.fpn_lateral4.{bias, weight}[0m
  [34mbackbone.fpn_lateral5.{bias, weight}[0m
  [34mbackbone.fpn_output2.{bias, weight}[0m
  [34mbackbone.fpn_output3.{bias, weight}[0m
  [34mbackbone.fpn_output4.{bias, weight}[0m
  [34mbackbone.fpn_output5.{bias, weight}[0m
  [34mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}[0m
  [34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
  [34mproposal_generator.rpn_head.conv.{bias, weight}[0m
  [34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
  [34mroi_heads.box_head.fc1.{bias, weight}[0m
  [34mroi_heads.box_head.fc2.{bias, weight}[0m
  [34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
  [34mroi_heads.box_predictor.cls_score.weight[0m
[32m[07/09 23:04:40 d2.checkpoint.c2_model_loading]: [0mThe checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000_b[0m
  [35mfc1000_w[0m
  [35mres2_0_branch2a_b[0m
  [35mres2_0_branch2b_b[0m
  [35mres2_0_branch2c_b[0m
  [35mres2_0_branch1_b[0m
  [35mres2_1_branch2a_b[0m
  [35mres2_1_branch2b_b[0m
  [35mres2_1_branch2c_b[0m
  [35mres2_2_branch2a_b[0m
  [35mres2_2_branch2b_b[0m
  [35mres2_2_branch2c_b[0m
  [35mres3_0_branch2a_b[0m
  [35mres3_0_branch2b_b[0m
  [35mres3_0_branch2c_b[0m
  [35mres3_0_branch1_b[0m
  [35mres3_1_branch2a_b[0m
  [35mres3_1_branch2b_b[0m
  [35mres3_1_branch2c_b[0m
  [35mres3_2_branch2a_b[0m
  [35mres3_2_branch2b_b[0m
  [35mres3_2_branch2c_b[0m
  [35mres3_3_branch2a_b[0m
  [35mres3_3_branch2b_b[0m
  [35mres3_3_branch2c_b[0m
  [35mres4_0_branch2a_b[0m
  [35mres4_0_branch2b_b[0m
  [35mres4_0_branch2c_b[0m
  [35mres4_0_branch1_b[0m
  [35mres4_1_branch2a_b[0m
  [35mres4_1_branch2b_b[0m
  [35mres4_1_branch2c_b[0m
  [35mres4_10_branch2a_b[0m
  [35mres4_10_branch2b_b[0m
  [35mres4_10_branch2c_b[0m
  [35mres4_11_branch2a_b[0m
  [35mres4_11_branch2b_b[0m
  [35mres4_11_branch2c_b[0m
  [35mres4_12_branch2a_b[0m
  [35mres4_12_branch2b_b[0m
  [35mres4_12_branch2c_b[0m
  [35mres4_13_branch2a_b[0m
  [35mres4_13_branch2b_b[0m
  [35mres4_13_branch2c_b[0m
  [35mres4_14_branch2a_b[0m
  [35mres4_14_branch2b_b[0m
  [35mres4_14_branch2c_b[0m
  [35mres4_15_branch2a_b[0m
  [35mres4_15_branch2b_b[0m
  [35mres4_15_branch2c_b[0m
  [35mres4_16_branch2a_b[0m
  [35mres4_16_branch2b_b[0m
  [35mres4_16_branch2c_b[0m
  [35mres4_17_branch2a_b[0m
  [35mres4_17_branch2b_b[0m
  [35mres4_17_branch2c_b[0m
  [35mres4_18_branch2a_b[0m
  [35mres4_18_branch2b_b[0m
  [35mres4_18_branch2c_b[0m
  [35mres4_19_branch2a_b[0m
  [35mres4_19_branch2b_b[0m
  [35mres4_19_branch2c_b[0m
  [35mres4_2_branch2a_b[0m
  [35mres4_2_branch2b_b[0m
  [35mres4_2_branch2c_b[0m
  [35mres4_20_branch2a_b[0m
  [35mres4_20_branch2b_b[0m
  [35mres4_20_branch2c_b[0m
  [35mres4_21_branch2a_b[0m
  [35mres4_21_branch2b_b[0m
  [35mres4_21_branch2c_b[0m
  [35mres4_22_branch2a_b[0m
  [35mres4_22_branch2b_b[0m
  [35mres4_22_branch2c_b[0m
  [35mres4_3_branch2a_b[0m
  [35mres4_3_branch2b_b[0m
  [35mres4_3_branch2c_b[0m
  [35mres4_4_branch2a_b[0m
  [35mres4_4_branch2b_b[0m
  [35mres4_4_branch2c_b[0m
  [35mres4_5_branch2a_b[0m
  [35mres4_5_branch2b_b[0m
  [35mres4_5_branch2c_b[0m
  [35mres4_6_branch2a_b[0m
  [35mres4_6_branch2b_b[0m
  [35mres4_6_branch2c_b[0m
  [35mres4_7_branch2a_b[0m
  [35mres4_7_branch2b_b[0m
  [35mres4_7_branch2c_b[0m
  [35mres4_8_branch2a_b[0m
  [35mres4_8_branch2b_b[0m
  [35mres4_8_branch2c_b[0m
  [35mres4_9_branch2a_b[0m
  [35mres4_9_branch2b_b[0m
  [35mres4_9_branch2c_b[0m
  [35mres5_0_branch2a_b[0m
  [35mres5_0_branch2b_b[0m
  [35mres5_0_branch2c_b[0m
  [35mres5_0_branch1_b[0m
  [35mres5_1_branch2a_b[0m
  [35mres5_1_branch2b_b[0m
  [35mres5_1_branch2c_b[0m
  [35mres5_2_branch2a_b[0m
  [35mres5_2_branch2b_b[0m
  [35mres5_2_branch2c_b[0m
  [35mconv1_b[0m
froze backbone parameters
froze proposal generator parameters
froze roi_box_head parameters
--------------------------------------------------------------------
voc_2007_trainval_all1_2shot_seed4
datasets/VOC2007
all_2shot_split_1_trainval
['aeroplane', 'bicycle', 'boat', 'bottle', 'car', 'cat', 'chair', 'diningtable', 'dog', 'horse', 'person', 'pottedplant', 'sheep', 'train', 'tvmonitor', 'bird', 'bus', 'cow', 'motorbike', 'sofa']
--------------------------------------------------------------------
** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

[32m[07/09 23:04:40 d2.engine.train_loop]: [0mStarting training from iteration 0
** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

** fvcore version of PathManager will be deprecated soon. **
** Please migrate to the version in iopath repo. **
https://github.com/facebookresearch/iopath 

Traceback (most recent call last):
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/zhanglibin/workspace/FSOD/few-shot-object-detection/tools/train_net.py", line 113, in <module>
    args=(args,),
  File "/home/zhanglibin/packages/detectron2_repo/detectron2/engine/launch.py", line 59, in launch
    daemon=False,
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 247, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 205, in start_processes
    while not context.join():
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 117, in join
    timeout=timeout,
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/multiprocessing/connection.py", line 921, in wait
    ready = selector.select(timeout)
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/multiprocessing/popen_fork.py", line 28, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt
[4m[5m[31mERROR[0m [32m[07/09 23:04:56 d2.engine.train_loop]: [0mException during training:
Traceback (most recent call last):
  File "/home/zhanglibin/packages/detectron2_repo/detectron2/utils/memory.py", line 70, in wrapped
    return func(*args, **kwargs)
  File "/home/zhanglibin/packages/detectron2_repo/detectron2/modeling/matcher.py", line 88, in __call__
    assert torch.all(match_quality_matrix >= 0)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zhanglibin/packages/detectron2_repo/detectron2/engine/train_loop.py", line 134, in train
    self.run_step()
  File "/home/zhanglibin/packages/detectron2_repo/detectron2/engine/train_loop.py", line 228, in run_step
    loss_dict = self.model(data)
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 744, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 684, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 744, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/zhanglibin/workspace/FSOD/few-shot-object-detection/fsdet/modeling/meta_arch/rcnn.py", line 115, in forward
    images, features, gt_instances
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 744, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/zhanglibin/packages/detectron2_repo/detectron2/modeling/proposal_generator/rpn.py", line 442, in forward
    gt_labels, gt_boxes = self.label_and_sample_anchors(anchors, gt_instances)
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/zhanglibin/packages/detectron2_repo/detectron2/modeling/proposal_generator/rpn.py", line 302, in label_and_sample_anchors
    matched_idxs, gt_labels_i = retry_if_cuda_oom(self.anchor_matcher)(match_quality_matrix)
  File "/home/zhanglibin/packages/detectron2_repo/detectron2/utils/memory.py", line 70, in wrapped
    return func(*args, **kwargs)
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 24230) is killed by signal: Interrupt. 
[32m[07/09 23:04:56 d2.engine.hooks]: [0mOverall training speed: 5 iterations in 0:00:09 (1.9180 s / it)
[32m[07/09 23:04:56 d2.engine.hooks]: [0mTotal training time: 0:00:09 (0:00:00 on hooks)
[32m[07/09 23:04:56 d2.utils.events]: [0m eta: 3:56:17  iter: 7  total_loss: 2.309  loss_cls: 1.579  loss_box_reg: 0.003732  loss_rpn_cls: 0.6923  loss_rpn_loc: 0.03381  time: 1.6957  data_time: 0.3125  lr: 0.001  max_mem: 11436M
/home/zhanglibin/workspace/FSOD/few-shot-object-detection/fsdet/modeling/roi_heads/fast_rcnn.py:198: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:982.)
  num_fg = fg_inds.nonzero().numel()
Process SpawnProcess-1:
Traceback (most recent call last):
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 61, in _wrap
    pass  # SIGINT; Killed by parent, do nothing
KeyboardInterrupt
/home/zhanglibin/workspace/FSOD/few-shot-object-detection/fsdet/modeling/roi_heads/fast_rcnn.py:198: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:982.)
  num_fg = fg_inds.nonzero().numel()
Exception ignored in: <generator object stream at 0x7f2c463aee50>
Traceback (most recent call last):
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/cuda/__init__.py", line 331, in stream
    yield
  File "/home/zhanglibin/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 24113) is killed by signal: Interrupt. 
